
#Importaci√≥n de librer√≠as
import nltk #Liber√≠a principal para el procesamiento del lenguaje natural
from nltk.corpus import wordnet as wn, stopwords
from nltk import word_tokenize, pos_tag, ne_chunk, FreqDist
import tkinter as tk
from tkinter import filedialog, scrolledtext, messagebox


def analizar_texto(texto):
    resultado = ""

    if not texto.strip():
        return "‚ö†Ô∏è No se ha ingresado texto"

#Tokenizaci√≥n
#Se divide el texto en una lista de palabras (tokens) y se convierten a min√∫sculas.
    tokens = word_tokenize(texto.lower(), language="spanish")

#Liempieza, solo se tomar√°n las palabras (sin signos ni n√∫meros) y se eliminar√°n las stopwords (palabras vac√≠as)
    tokens_limpios = [t for t in tokens if t.isalpha()]

# Se carga el conjunto de "stopwords" (palabras comunes sin valor sem√°ntico) en espa√±ol.

    stop_words = set(stopwords.words("spanish"))
    tokens_filtrados = [t for t in tokens_limpios if t not in stop_words]

#N√∫mero de palabras reales
    num_palabras = len(tokens_filtrados)  #Se corrigi√≥ y se agreg√≥ la filtraci√≥n para contar palabras "reales"
    resultado += f"üìå N√∫mero total de palabras: {num_palabras}\n\n"

#Frecuencia de t√©rminos
    fdist = FreqDist(tokens_filtrados)
    top_terminos = fdist.most_common(5)
    resultado += "üìå T√©rminos clave m√°s comunes:\n"
    for palabra, frecuencia in top_terminos:
        resultado += f"{palabra}: {frecuencia}\n"
    resultado += "\n"

#Sin√≥nimos para los t√©rminos clave
    resultado += "üìå Sin√≥nimos de los t√©rminos clave:\n"
    for palabra, _ in top_terminos:
        synsets = wn.synsets(palabra, lang="spa") #Se busca la palabra en wordnet
        sinonimos = set() #Evitamos sin√≥nimos duplicados
        for syn in synsets:
            for lemma in syn.lemmas("spa"):
                sinonimos.add(lemma.name())
        if sinonimos:
            resultado += f"- {palabra}: {', '.join(list(sinonimos)[:5])}\n" #Se proporcionan los primeros 5 resultados
        else:
            resultado += f"- {palabra}: (no se encontraron sin√≥nimos)\n"
    resultado += "\n"

    # ... (previous code)

    #Reconocimiento de Entidades Nombradas (NER)
    tokens_origen = word_tokenize(texto, language="spanish") #se agreg√≥ el idioma a espa√±ol
    etiquetas = pos_tag(tokens_origen)     # Primero, se etiqueta cada palabra con su categor√≠a gramatical (nombre, verbo, adjetivo, etc.)
    arbol_entidades = ne_chunk(etiquetas) #agrupa las palabras con su categor√≠a gramatical
    resultado += "üìå Entidades reconocidas en el texto:\n"
    for subtree in arbol_entidades:
        if hasattr(subtree, "label"):
            entidad = " ".join(c[0] for c in subtree.leaves())
            resultado += f"{subtree.label()}: {entidad}\n"
    resultado += "\n"

    # --- SISTEMA EXPERTO: Clasificaci√≥n de Tema ---
    resultado += sistema_experto_clasificacion(tokens_limpios)
    
    return resultado


def sistema_experto_clasificacion(tokens):
    """
    Sistema experto simple basado en reglas para clasificar el tema del texto.
    Base de conocimiento: Diccionario de palabras clave.
    Motor de inferencia: Conteo de coincidencias y selecci√≥n de m√°ximo.
    """
    # Base de conocimiento
    base_conocimiento = {
        "Tecnolog√≠a": ["computadora", "software", "hardware", "inteligencia", "artificial", "internet", "redes", "algoritmo", "datos", "programaci√≥n", "c√≥digo", "app", "digital", "robot", "cibern√©tico"],
        "Ciencia": ["f√≠sica", "qu√≠mica", "biolog√≠a", "espacio", "teor√≠a", "experimento", "cient√≠fico", "√°tomo", "mol√©cula", "energ√≠a", "c√©lula", "astronom√≠a", "gen√©tica"],
        "Deportes": ["f√∫tbol", "baloncesto", "tenis", "gol", "partido", "jugador", "equipo", "torneo", "campeonato", "medalla", "ol√≠mpico", "entrenador", "atleta", "carrera"],
        "Pol√≠tica": ["gobierno", "ley", "elecciones", "presidente", "ministro", "democracia", "voto", "parlamento", "pol√≠tica", "naci√≥n", "naciones", "estado", "candidato", "partido", "organizaci√≥n", "unidas"],
        "Arte/Cultura": ["m√∫sica", "pintura", "cine", "literatura", "poes√≠a", "escultura", "artista", "obra", "museo", "concierto", "teatro", "novela", "autor", "escritor", "libro", "escribi√≥"]
    }

    # Motor de inferencia
    puntuaciones = {tema: 0 for tema in base_conocimiento}
    
    for token in tokens:
        for tema, palabras_clave in base_conocimiento.items():
            if token in palabras_clave:
                puntuaciones[tema] += 1

    # Reglas de decisi√≥n
    tema_detectado = "General / No identificado"
    max_puntos = 0
    
    for tema, puntos in puntuaciones.items():
        if puntos > max_puntos:
            max_puntos = puntos
            tema_detectado = tema
            
    # Umbral m√≠nimo
    if max_puntos < 1:
        tema_detectado = "General / No identificado"

    return f"üìå Clasificaci√≥n de Tema (Sistema Experto): {tema_detectado} (Coincidencias: {max_puntos})\n"


#Funci√≥n para bot√≥n "Analizar"
def ejecutar_analisis():
    texto = entrada_texto.get("1.0", tk.END)
    try:
        resultado = analizar_texto(texto)
        salida_texto.delete("1.0", tk.END)
        salida_texto.insert(tk.END, resultado)
    except Exception as e:
        messagebox.showerror("Error en an√°lisis", str(e))


#Funci√≥n para cargar archivo txt
def cargar_archivo():
    archivo = filedialog.askopenfilename(filetypes=[("Archivos de texto", "*.txt")])
    if archivo:
        try:
            with open(archivo, "r", encoding="utf-8") as f:
                contenido = f.read()
                entrada_texto.delete("1.0", tk.END)
                entrada_texto.insert(tk.END, contenido)
        except Exception as e:
            messagebox.showerror("Error", f"No se pudo abrir el archivo: {e}")

#Funci√≥n para limpiar o borrar el texto introducido
def limpiar_texto():
    entrada_texto.delete("1.0", tk.END)
    salida_texto.delete("1.0", tk.END)



#Interfaz gr√°fica (Tkinter)
if __name__ == "__main__":
    ventana = tk.Tk()
    ventana.title("Analizador de Textos Academicos Equipo 11")
    ventana.geometry("850x650")

#Etiqueta
    tk.Label(ventana, text="Introduce un texto acad√©mico o carga un archivo .txt:",
            font=("Arial", 12)).pack(pady=5)

#Cuadro de texto para entrada
    entrada_texto = scrolledtext.ScrolledText(ventana, wrap=tk.WORD, width=95, height=10)
    entrada_texto.pack(padx=10, pady=10)

#Botones
    frame_botones = tk.Frame(ventana)
    frame_botones.pack()

    btn_analizar = tk.Button(frame_botones, text="Analizar", command=ejecutar_analisis, bg="lightgreen")
    btn_analizar.grid(row=0, column=0, padx=5)

    btn_cargar = tk.Button(frame_botones, text="Cargar archivo .txt", command=cargar_archivo, bg="lightblue")
    btn_cargar.grid(row=0, column=1, padx=5)

    btn_limpiar = tk.Button(frame_botones, text="Limpiar", command=limpiar_texto, bg="salmon")
    btn_limpiar.grid(row=0, column=2, padx=5)

#Cuadro de texto para salida
    tk.Label(ventana, text="Resultados del an√°lisis:",
            font=("Arial", 12)).pack(pady=5)

    salida_texto = scrolledtext.ScrolledText(ventana, wrap=tk.WORD, width=95, height=20, state="normal")
    salida_texto.pack(padx=10, pady=10)

    ventana.mainloop()
